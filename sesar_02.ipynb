{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import spacy\n",
    "import pprint\n",
    "import IPython\n",
    "import spotlight\n",
    "import subprocess\n",
    "import readability \n",
    "import urllib.parse \n",
    "import urllib.request  \n",
    "from random import randint\n",
    "from subprocess import call\n",
    "from subprocess import Popen,PIPE\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_metadata():\n",
    "    global metadata\n",
    "    metadata = str(sys.argv[1:])\n",
    "    if \"-f\" in metadata:\n",
    "        metadata = filename_widget.value\n",
    "        print(metadata)\n",
    "    else:\n",
    "        filename_clean = metadata.replace(\"[\",\"\")\n",
    "        filename_cleaner = filename_clean.replace(\"'\",\"\")\n",
    "        metadata = filename_cleaner.replace(\"]\",\"\")\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FUNCTION A: creates a text input from an argument which has to be typed in the following form:\n",
    "#################  \"Hello, this is a new sentence. And this is a newer one\"\n",
    "def select_text_input():\n",
    "    global text_for_pipeline\n",
    "    text_from_commandline = str(sys.argv[2:])\n",
    "    if \"/\" in text_from_commandline:\n",
    "        text_for_pipeline = text_widget.value\n",
    "    elif text_from_commandline:\n",
    "        text_clean = text_from_commandline.replace(\"[\",\"\")\n",
    "        text_cleaner = text_clean.replace(\"'\",\"\")\n",
    "        text_for_pipeline = text_cleaner.replace(\"]\",\"\")\n",
    "        return text_for_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTION B: loads a file of .json-format, in order to read the \"text input\"-value and to modify it. \n",
    "def read_json_metadata():\n",
    "    global robot_metadata\n",
    "    global text_for_spacy\n",
    "    global received_data\n",
    "    text_from_json = received_data[\"metadata\"][\"input_text\"]\n",
    "    if text_from_json != 'None':\n",
    "        received_data[\"metadata\"][\"input_text\"] = text_for_pipeline\n",
    "        text_for_spacy = received_data[\"metadata\"][\"input_text\"]\n",
    "        robot_metadata.seek(0)\n",
    "        robot_metadata.write(json.dumps(received_data, sort_keys = True,  indent=4))\n",
    "        robot_metadata.truncate()\n",
    "        print('Text voor SpaCy:', text_for_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FUNCTION C: Matches (a) given string(s) to an entity in DBPedia. Returns the structured data of the entity \n",
    "#in the form of a dictionary\n",
    "def link_to_dbpedia(doc):\n",
    "    query = doc\n",
    "    urlPostPrefixSpotlight = \"http://spotlight.sztaki.hu:2222/rest/annotate\"\n",
    "    args = urllib.parse.urlencode([(\"text\", query), (\"confidence\", 0), (\"support\", 0)]).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(urlPostPrefixSpotlight, data=args, headers={\"Accept\": \"application/json\"})\n",
    "    response = urllib.request.urlopen(request).read()\n",
    "    dbpedia_ent_dict = json.loads(response.decode('utf-8'))\n",
    "    return dbpedia_ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTION D: Extracts the metadata of the entity in Matches (a) given string(s) to an entity in DBPedia.\n",
    "def extract_entity_values(entity):\n",
    "    dbp_resrc = entity['Resources']\n",
    "    for dbp_resrc_dict in dbp_resrc:\n",
    "        ent_name_in_dbp = dbp_resrc_dict['@surfaceForm']\n",
    "        ent_type_in_dbp = dbp_resrc_dict['@types']\n",
    "        ent_uri_in_dbp = dbp_resrc_dict['@URI']\n",
    "        ent_conf_in_dbp = dbp_resrc_dict['@similarityScore']\n",
    "        dbp_resrc_dict\n",
    "        return (ent_name_in_dbp, ent_type_in_dbp, ent_uri_in_dbp, ent_conf_in_dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_entity_dict(selected_values):\n",
    "    dbp_keys = ('name','type','URI','confidence')\n",
    "    ent_dict = dict(zip(dbp_keys, selected_values))\n",
    "    ent_id = 'ent'+str(randint(0,100))\n",
    "    dict_of_defined_entity = {}\n",
    "    dict_of_defined_entity[ent_id] = ent_dict\n",
    "    return dict_of_defined_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def semantic_processing_with_dpbedia():\n",
    "    for entity in doc.ents:\n",
    "        entity_in_dbpedia = link_to_dbpedia(entity)\n",
    "        dbp_values = extract_entity_values(entity_in_dbpedia)\n",
    "        interpreted_entity = create_entity_dict(dbp_values)\n",
    "        if entity.label_ == 'GPE':\n",
    "            received_data['semantic']['places'].update(interpreted_entity)\n",
    "        if entity.label_ == 'ORG':\n",
    "            received_data['semantic']['organisations'].update(interpreted_entity)\n",
    "        if entity.label_ == 'PERSON':\n",
    "            received_data['semantic']['people'].update(interpreted_entity)\n",
    "        robot_metadata.seek(0)\n",
    "        robot_metadata.write(json.dumps(received_data, sort_keys = True, indent=4))\n",
    "        robot_metadata.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dict_of_words_vs_postags():\n",
    "    global dict_of_words\n",
    "    dict_of_words = {}\n",
    "    for word in doc:\n",
    "        dict_of_words[word.string] = word.tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CREATES A FUNCTION THAT GENERATES A DICTIONARY OF CONTENT WORD (EMOTION?)\n",
    "def create_dict_of_content_words():\n",
    "    global dict_of_content_words\n",
    "    dict_of_content_words = {}\n",
    "    for word in doc:\n",
    "        if 'NN' in word.tag_:\n",
    "            dict_of_content_words[word.string] = word.tag_\n",
    "        if 'VB' in word.tag_:\n",
    "            dict_of_content_words[word.string] = word.tag_\n",
    "        if 'JJ' in word.tag_:\n",
    "            dict_of_content_words[word.string] = word.tag_\n",
    "        if 'RB' in word.tag_:\n",
    "            dict_of_content_words[word.string] = word.tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emotion_recognition(inputtext):\n",
    "    sentence = inputtext\n",
    "    global modif_dict\n",
    "    global dict_scored_emotions\n",
    "    modif_dict = {}\n",
    "    dict_scored_emotions = {}\n",
    "\n",
    "    #proc = subprocess.Popen([ 'echo \"i am really very angry with the government not taking care of things.\" | ./emotionStream.sh'], stdout=subprocess.PIPE, shell=True)\n",
    "    proc = subprocess.Popen([ 'echo {} | ./emotionStream.sh'.format(sentence)], stdout=subprocess.PIPE, shell=True)\n",
    "    (out, err) = proc.communicate()\n",
    "    decoded_output = out.decode()\n",
    "\n",
    "    modif_unclean = decoded_output.split('][')[1]\n",
    "    modif = modif_unclean.replace(\"'\",\"\")  \n",
    "    modif_list = modif.split(',')\n",
    "    emotions_unclean = decoded_output.split('][')[2]\n",
    "    emotions = emotions_unclean.replace(\"'\",\"\")  \n",
    "    emotions_list = emotions.split(',')\n",
    "    \n",
    "    for entry in modif_list:\n",
    "        key_unclean = entry.split(':')[0]\n",
    "        key = key_unclean.replace('\"','') \n",
    "        value_unclean = entry.split(':')[1]\n",
    "        value = value_unclean.replace('\"','')\n",
    "        modif_dict[key] = value\n",
    "    for entry in emotions_list:\n",
    "        key_unclean = entry.split(':')[0]\n",
    "        key = key_unclean.replace('\"','') \n",
    "        value_notclean = entry.split(':')[1]\n",
    "        value_unclean = value_notclean.replace(']','')\n",
    "        value_as_string = value_unclean.replace('\"','')\n",
    "        value = int(value_as_string)\n",
    "        if value != 0:\n",
    "            dict_scored_emotions[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emotions_extraction():\n",
    "    for emotion in dict_scored_emotions:\n",
    "        received_data['emotions']['detected_emotion'].append(emotion)\n",
    "        robot_metadata.seek(0)\n",
    "        robot_metadata.write(json.dumps(received_data, sort_keys = True, indent=4))\n",
    "        robot_metadata.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#STRUCTURAL PROCESSOR (FUNCTION) NEEDS TO BE DEFINED\n",
    "def structural_processor(): \n",
    "    received_data['structure']['wordcount'] = int(len(dict_of_words))\n",
    "    for sent in doc.sents:\n",
    "        received_data['structure']['number_of_sentences'] += 1    \n",
    "    for word in doc:      \n",
    "        if 'JJ' in word.tag_:\n",
    "            received_data['structure']['adjective_count'] += 1 \n",
    "        if 'RB' in word.tag_:\n",
    "            received_data['structure']['adverbs'] += 1\n",
    "        if 'PRP' in word.tag_:\n",
    "            received_data['structure']['personal_pronouns'] += 1\n",
    "        if 'VBD' in word.tag_:\n",
    "            received_data['structure']['non_future'] += 1\n",
    "        if 'VBN' in word.tag_:\n",
    "            received_data['structure']['non_future'] += 1\n",
    "        if 'VB' in word.tag_: \n",
    "            received_data['structure']['future'] += 1\n",
    "        if 'VBG' in word.tag_:\n",
    "            received_data['structure']['future'] += 1            \n",
    "        if 'VBP' in word.tag_: \n",
    "            received_data['structure']['future'] += 1\n",
    "        if 'VBZ' in word.tag_:  \n",
    "            received_data['structure']['future'] += 1\n",
    "        robot_metadata.seek(0)\n",
    "        robot_metadata.write(json.dumps(received_data, sort_keys = True, indent=4))\n",
    "        robot_metadata.truncate()\n",
    "    for dependancy in doc:\n",
    "        if dependancy.dep_ == 'neg':\n",
    "            received_data['structure']['negations'] += 1\n",
    "        if dependancy.dep_ == 'prep':\n",
    "            received_data['structure']['prepositional_phrases_count'] += 1\n",
    "        if dependancy.dep_ == 'aux':\n",
    "            received_data['structure']['active_sentences'] += 1\n",
    "        if dependancy.dep_ == 'auxpass':\n",
    "            received_data['structure']['passive_sentences'] += 1\n",
    "        robot_metadata.seek(0)\n",
    "        robot_metadata.write(json.dumps(received_data, sort_keys = True, indent=4))\n",
    "        robot_metadata.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ENTER THE NAME OF DEMO INPUT FILE: sample_input.json\n",
    "def demos_file():\n",
    "    global filename_widget\n",
    "    filename_widget = widgets.Text()\n",
    "    display(filename_widget)\n",
    "    def handle_submit(sender):\n",
    "        print(filename_widget.value)        \n",
    "    filename_widget.on_submit(handle_submit) \n",
    "demos_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ENTER THE NAME OF DEMO INPUT FILE: We are looking for Richard Franzen an American who has built a robot. He resides in Tagoyashi.\n",
    "def demos_text():\n",
    "    global text_widget\n",
    "    text_widget = widgets.Text()\n",
    "    display(text_widget)\n",
    "    def handle_submit(sender):\n",
    "        print(text_widget.value)        \n",
    "    text_widget.on_submit(handle_submit)\n",
    "demos_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PROCESSING SEQUENCE 1: Execute all defined functions\n",
    "#metadata_cleaning() ---function not defined yet\n",
    "select_metadata()\n",
    "with open(metadata, 'r+') as robot_metadata:  \n",
    "    select_text_input()\n",
    "    received_data = json.load(robot_metadata)\n",
    "    read_json_metadata()\n",
    "    global doc\n",
    "    doc = nlp(text_for_spacy)\n",
    "    semantic_processing_with_dpbedia()\n",
    "    create_dict_of_words_vs_postags()\n",
    "    create_dict_of_content_words() \n",
    "    structural_processor()        \n",
    "    emotion_recognition(doc)\n",
    "    emotions_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#READABILITY FUNCT\n",
    "#import readability \n",
    "#text = \"We are looking for Richard Franzen, an American who has built a robot, he resides in Tagoyashi.\"\n",
    "#def structure_processor(text):\n",
    "#    result = readability.getmeasures(text)\n",
    "#    print(result)\n",
    "#    return result  \n",
    "#structure_processor()\n",
    "# MvE to do: output it to the right json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {
    "38b66d3c85d94460b4d6a856cad2ef19": {
     "views": [
      {
       "cell_index": 9.0
      }
     ]
    },
    "ddc5a42b9e4d486f98e113980b82762d": {
     "views": [
      {
       "cell_index": 8.0
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}