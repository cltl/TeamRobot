{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time \n",
    "import spotlight\n",
    "import subprocess\n",
    "import urllib.parse \n",
    "import urllib.request  \n",
    "from random import randint   \n",
    "from subprocess import call\n",
    "from subprocess import Popen,PIPE\n",
    "from modules import emotion as emotion_mod\n",
    "from modules import response_new as response_mod\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag.stanford import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_text_input():\n",
    "    text_for_nlp = str(sys.argv[2:])    \n",
    "    if \"/Users/\" in text_for_nlp:\n",
    "        text_for_nlp = \"I hate and am angry at stupid abandoning brundage\"\n",
    "    return text_for_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_json(text):\n",
    "    metadata = str(sys.argv[1])\n",
    "    if \"-f\" in metadata:\n",
    "        metadata_ep_sc = \"metadata/e_s.json\"\n",
    "    loaded_metadata = open(metadata_ep_sc,'r+')\n",
    "    meta_dd = json.load(loaded_metadata)  \n",
    "    episode_scene = metadata_ep_sc.strip(\".json\").split(\"/\")[1]\n",
    "    meta_dd[\"metadata\"][\"episode_id\"], meta_dd[\"metadata\"][\"scene_id\"] = episode_scene.split(\"_\")\n",
    "    timestamp = time.strftime(\"%y-%m-%dT%H:%M:%S\")\n",
    "    meta_dd['metadata']['timestamp'] = timestamp\n",
    "    text_from_json = meta_dd[\"metadata\"][\"input_text\"]\n",
    "    if text_from_json != 'None':\n",
    "        meta_dd[\"metadata\"][\"input_text\"] = text\n",
    "    return metadata_ep_sc, meta_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_exact_concepts(text):\n",
    "    list_of_words = []\n",
    "    for word,tag in nltk.pos_tag(word_tokenize(text)):\n",
    "        if tag == 'NN':\n",
    "            list_of_words.append(word)\n",
    "    return(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_potential_concepts(list_words):\n",
    "    potential_concepts = {}\n",
    "    for potential_concept in list_words:\n",
    "        potential_concepts['pcid'+str(randint(10,99))] = potential_concept\n",
    "    return potential_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emotion_processor(text_input):\n",
    "    sentence = text_input \n",
    "    modifier_dict = {}\n",
    "    emotions_dict = {}\n",
    "    emotions_score_dict = {}\n",
    "    proc = subprocess.Popen(['echo {} | ./emotionStream.sh'.format(sentence)], stdout=subprocess.PIPE, shell=True)\n",
    "    (out, err) = proc.communicate()      \n",
    "    emotions = out.decode().split('],')[0].split(\":[\")[1:][0].strip(\"{}}]\").split(\",\") \n",
    "    for emotion in emotions:\n",
    "        item0, value0 = emotion.split(\":\")\n",
    "        item = item0.strip('\"')\n",
    "        value = int(value0.strip('\"'))\n",
    "        emotions_dict[item] = value\n",
    "    for key, value in emotions_dict.items():\n",
    "        emotions_score_dict[key] = value\n",
    "        meta_dd['emotions']['detected_emotion'] = emotions_score_dict\n",
    "    return emotions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dict_per_concept(type_,conceptmention):\n",
    "    concept_dict = {}\n",
    "    concept_dict['mention'] = conceptmention\n",
    "    concept_dict['types'] = type_\n",
    "    concept_dict['dbp_uri'] = '' \n",
    "    concept_dict['timestamp'] = timestamp_log\n",
    "    return concept_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_hotlist_one(meta_dd, pcid, pot_con):\n",
    "    hotlist1 = open(\"knowledge/hotlist_1.json\", \"r+\")\n",
    "    hotlist1_dict = json.load(hotlist1)\n",
    "    extracted_concept = pot_con\n",
    "    concept = {}\n",
    "    for episode,paper in hotlist1_dict.items():\n",
    "        for papercode, paper in paper.items():\n",
    "            prvn = paper['authors']\n",
    "            if len(prvn) == 2:\n",
    "                name_val = str(prvn['name']).lower()\n",
    "                if extracted_concept in name_val:\n",
    "                    concept.update({'Author' : name_val})\n",
    "                inst_val = str(prvn['institution']).lower()\n",
    "                if extracted_concept in inst_val:\n",
    "                    concept.update({'Institution' : (str(prvn['institution']))})\n",
    "            if len(prvn) == 1:            \n",
    "                if 'name' in prvn.keys():\n",
    "                    name_val = str(prvn['name']).lower()\n",
    "                    if extracted_concept in str(prvn['name']):\n",
    "                        concept.update({'Author' : (str(prvn['name']))})\n",
    "                if 'institution' in prvn.keys():\n",
    "                    inst_val = str(prvn['institution']).lower()\n",
    "                    if extracted_concept in str(prvn['institution']):\n",
    "                        concept.update({'Institution' : (str(prvn['institution']))})\n",
    "    for type_,concept_sf in concept.items():\n",
    "        concept_dictionary = create_dict_per_concept(type_,concept_sf)\n",
    "        ent_id = \"ent\"+str(randint(10,99))\n",
    "        if type_ == \"Author\":\n",
    "            meta_dd['semantic']['authors'].update({ent_id:concept_dictionary})\n",
    "        if type_ == \"Institution\":\n",
    "            meta_dd['semantic']['institutions'].update({ent_id:concept_dictionary})\n",
    "        return extracted_concept, concept_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_definitive_concepts(concept):\n",
    "    concept_code = \"defcon\"+str(randint(10,99))\n",
    "    dictionary_of_concepts.update({concept_code:concept})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_hotlist_zero(concept_code, matched_concept):\n",
    "    if matched_concept != None:\n",
    "        hotlist_0_dict.update({concept_code : matched_concept})\n",
    "    return hotlist_0_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conversation_log = {}\n",
    "hotlist_0_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion found: Negative with an emotion ratio of 0.1875\n",
      "How do you feel about miles brundage?\n"
     ]
    }
   ],
   "source": [
    "'---PIPELINE RUNNING--------------------------------------------------------------------'\n",
    "timestamp_log = time.strftime(\"D%y%m%d_T%H%M%S\")\n",
    "text = select_text_input()\n",
    "metadata, meta_dd = load_json(text)\n",
    "list_of_words = get_exact_concepts(text)\n",
    "potent_con = map_potential_concepts(list_of_words)\n",
    "emotion_processor(text)\n",
    "dictionary_of_concepts = {}\n",
    "for pcid, potential_concept in potent_con.items():\n",
    "    conceptdict = query_hotlist_one(meta_dd, pcid, potential_concept)\n",
    "    filter_definitive_concepts(conceptdict)  \n",
    "for conc_id,concept in dictionary_of_concepts.items():\n",
    "    hotlist_0_dict = update_hotlist_zero(conc_id,concept)\n",
    "with open('knowledge/hotlist_0.json', 'w+') as hotlist_zero:\n",
    "    hotlist_zero.write(json.dumps(hotlist_0_dict, sort_keys = True, indent=4))        \n",
    "conversation_log.update({metadata.strip('.json')+\"_\"+timestamp_log : meta_dd})\n",
    "with open('memory/e01_s01_inproces.json', 'w+') as scene:\n",
    "    scene.write(json.dumps(conversation_log, sort_keys = True, indent=4))\n",
    "#Grabs the emotion and emoratio\n",
    "emotion,emoratio = emotion_mod.emotion_ratio(meta_dd['emotions']['detected_emotion'], 16)\n",
    "print (\"Emotion found: {} with an emotion ratio of {}\".format(emotion,emoratio))\n",
    "generated_response = response_mod.generate_response(meta_dd['semantic'], emotion, emoratio)\n",
    "print(generated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}