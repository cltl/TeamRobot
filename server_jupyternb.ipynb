{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "from random import randint\n",
    "from modules import emotion as emotion_mod\n",
    "from modules import response as response_mod\n",
    "from knowledge import h2_loader_v2\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from pprint import pprint\n",
    "hl2 = h2_loader_v2.hotlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'---------FUNCTIONS-------------------------------------------------------------------------------'\n",
    "def load_json(text):\n",
    "    metadata_ep_sc = \"metadata/e_s.json\"\n",
    "    loaded_metadata = open(metadata_ep_sc,'r+')\n",
    "    meta_dd = json.load(loaded_metadata)\n",
    "    episode_scene = metadata_ep_sc.strip(\".json\").split(\"/\")[1]\n",
    "    meta_dd[\"metadata\"][\"episode_id\"], meta_dd[\"metadata\"][\"scene_id\"] = episode_scene.split(\"_\")\n",
    "    timestamp = time.strftime(\"%y-%m-%dT%H:%M:%S\")\n",
    "    meta_dd['metadata']['timestamp'] = timestamp\n",
    "    text_from_json = meta_dd[\"metadata\"][\"input_text\"]\n",
    "    if text_from_json != 'None':\n",
    "        meta_dd[\"metadata\"][\"input_text\"] = text\n",
    "    return metadata_ep_sc, meta_dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nouns(text):\n",
    "    words = []\n",
    "    list_of_tokens = ['i','you','man','night']\n",
    "    for word,tag in nltk.pos_tag(word_tokenize(text)):\n",
    "        if word not in list_of_tokens:\n",
    "            if tag == 'NN':\n",
    "                words.append(word)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_potential_concepts(words):\n",
    "    potential_concepts = {}\n",
    "    concept_id = 1\n",
    "    for potential_concept in words:\n",
    "        potential_concepts['pcid'+str(concept_id)] = potential_concept\n",
    "        concept_id += 1\n",
    "    return potential_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emotion_processor(text, meta_dd):\n",
    "    processor = subprocess.Popen(['echo {} | ./emotionStream.sh'.format(text)], stdout=subprocess.PIPE, shell=True)\n",
    "    processor_output, _ = processor.communicate()\n",
    "    decoded_output = processor_output.decode()\n",
    "    emotions_dict = json.loads(decoded_output)['emotion'][0]\n",
    "    meta_dd['emotions']['detected_emotion'] = emotions_dict\n",
    "    return emotions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict_per_concept(type_,conceptmention, timestamp):\n",
    "    concept_dict = {}\n",
    "    if type_ == \"Author\":\n",
    "        data = conceptmention.split(\"<\")\n",
    "        conceptmention = data[0]\n",
    "        data = data[1].split(\">\")\n",
    "        concept_dict['paper'] = data[0]\n",
    "        if data[1] != 'none':\n",
    "            concept_dict['institution'] = data[1]\n",
    "    concept_dict['mention'] = conceptmention\n",
    "    concept_dict['types'] = type_\n",
    "    concept_dict['dbp_uri'] = ''\n",
    "    concept_dict['timestamp'] = timestamp\n",
    "    return concept_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_hotlist_one(meta_dd, pcid, pot_con, timestamp):\n",
    "    hotlist1 = open(\"knowledge/hotlist_1.json\", \"r+\", encoding='utf-8')\n",
    "    hotlist1_dict = json.load(hotlist1)\n",
    "    extracted_concept = pot_con\n",
    "    concept = {}\n",
    "    for _,paper in hotlist1_dict.items():\n",
    "        for _, paper in paper.items():\n",
    "            prvn = paper['authors']\n",
    "            if len(prvn) == 2:\n",
    "                name_val = str(prvn['name']).lower()\n",
    "                if extracted_concept == name_val:\n",
    "                    try:\n",
    "                        inst_val = str(prvn['institution']).lower()\n",
    "                    except KeyError:\n",
    "                        inst_val = 'none'\n",
    "                    paper_name = str(paper['title'])\n",
    "                    name_val += \"<\" + paper_name + \">\" + inst_val\n",
    "\n",
    "                    concept.update({'Author' : name_val})\n",
    "                inst_val = str(prvn['institution']).lower()\n",
    "                if extracted_concept in inst_val:\n",
    "                    concept.update({'Institution' : (str(prvn['institution']))})\n",
    "            if len(prvn) == 1:\n",
    "                if 'name' in prvn.keys():\n",
    "                    name_val = str(prvn['name']).lower()\n",
    "                    if extracted_concept in str(prvn['name']):\n",
    "                        try:\n",
    "                            inst_val = str(prvn['institution']).lower()\n",
    "                        except KeyError:\n",
    "                            inst_val = 'none'\n",
    "                        paper_name = str(paper['title'])\n",
    "                        name_val += \"<\" + paper_name + \">\" + inst_val\n",
    "\n",
    "                        concept.update({'Author': name_val})\n",
    "                if 'institution' in prvn.keys():\n",
    "                    inst_val = str(prvn['institution']).lower()\n",
    "                    if extracted_concept in str(prvn['institution']):\n",
    "                        concept.update({'Institution' : (str(prvn['institution']))})\n",
    "    for type_,concept_sf in concept.items():\n",
    "        concept_dictionary = create_dict_per_concept(type_,concept_sf, timestamp)\n",
    "        ent_id = \"ent\"+str(randint(10,99))\n",
    "        if type_ == \"Author\":\n",
    "            meta_dd['semantic']['authors'].update({ent_id:concept_dictionary})\n",
    "        if type_ == \"Institution\":\n",
    "            meta_dd['semantic']['institutions'].update({ent_id:concept_dictionary})\n",
    "        return extracted_concept, concept_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_hotlist_two(meta_dd, pcid, pot_con, timestamp, hl2):    \n",
    "    hotlist2 = hl2\n",
    "    pprint(\"Extracted concept: {}\".format(pot_con))\n",
    "    for instance in hotlist2:\n",
    "        name = instance['uri'].split('/')[-1]\n",
    "        name = name.replace('_', ' ').replace('-', ' ').lower()\n",
    "        if pot_con in name:\n",
    "            print(name)\n",
    "            for type_ in instance['types']:\n",
    "                if \"/Place\" in type_:\n",
    "                    ent_id = \"plc\" + (str(randint(10, 99)))\n",
    "                    instance['mention'] = pot_con\n",
    "                    instance['type'] = \"cities\"\n",
    "                    meta_dd['semantic']['cities'].update({ent_id: instance})\n",
    "                if \"Institution\" in type_:\n",
    "                    ent_id = \"ins\" + (str(randint(10, 99)))\n",
    "                    instance['mention'] = pot_con\n",
    "                    instance['type'] = \"institutions\"\n",
    "                    meta_dd['semantic']['institutions'].update({ent_id: instance})\n",
    "                if \"/Person\" in type_:\n",
    "                    ent_id = \"per\" + (str(randint(10, 99)))\n",
    "                    instance['mention'] = pot_con\n",
    "                    instance['type'] = \"authors\"\n",
    "                    meta_dd['semantic']['authors'].update({ent_id: instance})\n",
    "            return meta_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_definitive_concepts(concept, dictionary_of_concepts):\n",
    "    concept_code = \"defcon\"+str(randint(10,99))\n",
    "    dictionary_of_concepts.update({concept_code:concept})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_hotlist_zero(concept_code, matched_concept, hotlist_0_dict):\n",
    "    if matched_concept != None:\n",
    "        hotlist_0_dict.update({concept_code : matched_concept})\n",
    "    return hotlist_0_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'---------LOADED-DICTIONARIES-------------------------------------------------------------------'\n",
    "conversation_log = {}\n",
    "hotlist_0_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'---------PIPELINE-RUNNING--------------------------------------------------------------------'\n",
    "def annotate_and_respond(text):\n",
    "    global conversation_log\n",
    "    global hotlist_0_dict\n",
    "\n",
    "    timestamp_log = time.strftime(\"D%y%m%d_T%H%M%S\")\n",
    "    metadata, meta_dd = load_json(text)\n",
    "    nouns = get_nouns(text)\n",
    "    potent_con = map_potential_concepts(nouns )\n",
    "    emotion_processor(text,meta_dd)\n",
    "    dictionary_of_concepts = {}\n",
    "\n",
    "    pprint(text)\n",
    "    \n",
    "    for pcid, potential_concept in potent_con.items():\n",
    "        conceptdict1 = query_hotlist_one(meta_dd, pcid, potential_concept, timestamp_log)    \n",
    "        filter_definitive_concepts(conceptdict1, dictionary_of_concepts)\n",
    "        conceptdict2 = query_hotlist_two(meta_dd, pcid, potential_concept, timestamp_log, hl2)\n",
    "        filter_definitive_concepts(conceptdict2, dictionary_of_concepts)\n",
    "\n",
    "    for conc_id, concept in dictionary_of_concepts.items():\n",
    "        hotlist_0_dict = update_hotlist_zero(conc_id, concept, hotlist_0_dict)\n",
    "\n",
    "    with open('knowledge/hotlist_0.json', 'w+') as hotlist_zero:\n",
    "        hotlist_zero.write(json.dumps(hotlist_0_dict, sort_keys=True, indent=4))\n",
    "\n",
    "    conversation_log.update({metadata.strip('.json') + \"_\" + timestamp_log: meta_dd})\n",
    "\n",
    "    with open('memory/e01_s01_inproces.json', 'w+') as scene:\n",
    "        scene.write(json.dumps(conversation_log, sort_keys=True, indent=4))\n",
    "\n",
    "    emotion, emoratio = emotion_mod.emotion_ratio(meta_dd['emotions']['detected_emotion'], len(text.split()))\n",
    "    print (\"Emotion found: {} with an emotion ratio of {}\".format(emotion, emoratio))\n",
    "    generated_response = response_mod.generate_response(meta_dd['semantic'], emotion, emoratio)\n",
    "    return generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'really hate and love very much in london'\n",
      "'Extracted concept: london'\n",
      "city of london\n",
      "Emotion found: Negative with an emotion ratio of 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Is there something about london that puts you off??'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotate_and_respond(\"really hate and love very much in london\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
